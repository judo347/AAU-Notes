##### Usability

Describes a quality in the design: "*The effectiveness, efficiency and satisfaction with which specified users can achieve specified goals in particular environments.*"

**Effectiveness:** the accuracy and completeness with which specified users can achieve specified goals in particular environments.

**Efficiency:** the resource expended in relation to the accuracy and completeness of goals achieved.

**Satisfaction:** the comfort and acceptability of the work system to its users and other people affected it its use.

#### Jakob Nielsen describes Usability as:

**Learnability:** How easy is it for users to accomplish basic tasks the first time they encounter the design?

**Efficiency:** Once users have learned the design, how quickly can they perform tasks?

**Memorability:** When users return to the design after a period of not using it, how easily can they reestablish proficiency?

**Errors:** How many errors do users make; how severe are these errors, and how easily can they recover from the errors?

**Satisfaction:** How pleasant is it to use the design?

#### Usability Testing

The study of users' interaction with a product.

Purpose:

- Identifying usability problem in a system
- Starting point for refinements of design.

Outcome:

- A ranked list of usability problems
- Knowledge about what works well.

#### How do we evaluate usability:

Inquiry (We try to understand users)

- PACT and particular gathering method. We need to understand the users in order to design and test  a program.

Testing

- Users test product design. Could be in an inspection room. (Like in Silicon Valley)

Inspection

- Testing of a design by an expect. So an expect would go trough the program and try to spot usability programs.

#### When to test?

![](.\img\10.png)

#### lab vs field test

Lab strengths

- The least obtrusive way to collect data.
- Allows communication "behind the scene".
- Allows many observers.
- High replicability and control.
- Demand characteristics.

Lab weaknesses

- Somewhat "sterile" environment.
- Test participants may feel like "lab monkeys".
- Questionable realism (ecological validly).

#### Usability testing

Representative users interact with design.

Task solving and/or "thinking-aloud".

Produces a ranked list of usability problems.

Pros

- Identifies problems very precisely.
- Gives first-hand insight into use.

Cons

- Test situation can be unnatural.
- Difficult and very time consuming.

#### Heuristic Inspection

Usability experts inpect a design using a checklist (heuristic).

Scenarios + relevant tasks can strucuture process.

Produces a ranked list of usablity problems.

Pros

- Quick and easy to conduct.
- No users required.
- 3-5 inspections finds 70% of all problems.

Cons

- High proportion of "cosmetic" problems.
- "False" usability problems.

#### The usability testing process (participants perspective)

Introduction -> solve tasks -> debriefing.

#### The usability testing process (our perspective)

Make sure everything is ready -> observation + data collection -> analysis -> problem list.

#### Activities in Usability Testing

![](.\img\11.png)

#### Below is further explanation of the above image:

**Planning: Context of use**

- Where is the design/system used?
  - Physical environment?
  - Social context?
- Who uses the design?
  - User profiles
- Why is the design used?
  - What do people use it for?
  - Work? Leisure? Other activities?
- How is the design used?
  - Typical interactions.
  - Relevant and realistic data.

**Planning: Test participants**

- Representative for the user group
  - Demographics.
  - Experience.
- Number of test subjects
  - Generalizability.
  - Quantitative conclusions.
  - Statistics.
- Using fellow students
  - Problematic.
  - Motivation.
  - Demographics and experience.

**Planning: Number of test participants**

- Number of participants vs Usability problems found: 3 = 60%, 4 = 75%, 7 = 90%, 15 = 100%.

**Planning: Decide on the tasks**

What are the basic tasks that representative users do with the system?

Is the while system part of the evaluation?

Can we create crystal clear tasks descriptions?

How long does it take to solve the tasks?

Some useful rules for defining tasks:

1. Make the tasks realistic.
2. Make the tasks actionable.
3. Avoid clues and descripting the steps.

Good tasks

- Represent real use of the system.
- Decribe the end reuslt.
- Motivate (why should they be solved?).
- Include relevant data (e.g. names).
- Group smaller sub-tasks together.

Typical problems

- Vague, unclear or general.
- Provides too much help.
- Contain jargon and unfamiliar terms.
- Forces the user into a specific sequence.

**Planning: Decide on what to measure and how**

Are all the components of usability relevant?

How will we collect data?

What are we going to measure?

Think aloud?

**Example of usability metrics**

Objective metrics:

- Effectiveness: how many tasks were completed.
- Efficiency: how fast were they completed.

Subjective (perceived) usability metrics

- Interview data
- Questionnaires (for example SUS, USE questionnaires)

![](.\img\12.png)

**Video recordings**

The whole scene? The screen? The surroundings?

**Equipment in the lab**

Motorized cameras, pc screen capture, camera remote control, video monitors, video mixer, quad-spiller, microphones and video recorders (DVD).

Or you could use your room and some recording software.

![](.\img\13.png)

**Debriefing**

Is done immediately after evaluation session.

Can include:

- Filling out a questionnaire with options.
- An interview: explaining particular events in the evaluation.
- Critiquing the interaction design.
- User suggestion solutions and design ideas.

Allow enough time for discussion.